+ python3 training/test.py --detector_path ./training/config/detector/clip_enhanced.yaml --test_dataset FaceForensics++ --weights_path ../deepfake-detection/weights/model.ckpt
['in_channels', 'out_channels', 'kernel_size', 'stride', 'padding', 'dilation', 'groups', 'bias', 'padding_mode', 'device', 'dtype']
spatial_count=0 keep_stride_count=0
model keys:
['feature_extractor.vision_model.embeddings.class_embedding', 'feature_extractor.vision_model.embeddings.patch_embedding.weight', 'feature_extractor.vision_model.embeddings.position_embedding.weight', 'feature_extractor.vision_model.pre_layrnorm.base_layer.weight', 'feature_extractor.vision_model.pre_layrnorm.base_layer.bias', 'feature_extractor.vision_model.pre_layrnorm.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.pre_layrnorm.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.post_layernorm.base_layer.weight', 'feature_extractor.vision_model.post_layernorm.base_layer.bias', 'feature_extractor.vision_model.post_layernorm.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.post_layernorm.ln_tuning_layers.default.bias', 'model.linear.weight', 'model.linear.bias']
===> Load checkpoint done!

Dataset: FaceForensics++
Number of images: 22388
Number of labels: 22388
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:08,  1.06it/s] 20%|██        | 2/10 [00:01<00:05,  1.42it/s] 30%|███       | 3/10 [00:02<00:04,  1.60it/s] 40%|████      | 4/10 [00:02<00:03,  1.69it/s] 50%|█████     | 5/10 [00:03<00:02,  1.75it/s] 60%|██████    | 6/10 [00:03<00:02,  1.79it/s] 70%|███████   | 7/10 [00:04<00:01,  1.82it/s] 80%|████████  | 8/10 [00:04<00:01,  1.83it/s] 90%|█████████ | 9/10 [00:05<00:00,  1.85it/s]100%|██████████| 10/10 [00:05<00:00,  1.85it/s]100%|██████████| 10/10 [00:05<00:00,  1.74it/s]

Detailed metrics for FaceForensics++:
True Negatives (Real classified as Real): 4
False Positives (Real classified as Fake): 58
False Negatives (Fake classified as Real): 15
True Positives (Fake classified as Fake): 243
Accuracy: 0.7719
Precision: 0.8073
Recall: 0.9419
F1 Score: 0.8694

Predictions shape: (320,)
Labels shape: (320,)
Number of processed images: 22388
Number of processed image names: 320
len(y_pred): 320
len(y_true): 320

dataset: FaceForensics++
acc: 0.771875
auc: 0.5109402350587647
eer: 0.4838709677419355
ap: 0.8021112954111808
pred: [0.6554273  0.70145303 0.58103764 0.5057538  0.5318132  0.58342654
 0.6562176  0.56685674 0.72252303 0.5528025  0.5547472  0.5476647
 0.49169394 0.5413291  0.61416954 0.53771234 0.6106822  0.5556192
 0.69309247 0.7102875  0.576874   0.56177855 0.75866127 0.65541077
 0.6218366  0.5160312  0.6148732  0.5301475  0.6549152  0.7101318
 0.5432124  0.76438737 0.67082757 0.7245096  0.5623826  0.65521127
 0.5842623  0.5284217  0.6632423  0.5535767  0.42645198 0.49335524
 0.50260985 0.53487337 0.565559   0.68730766 0.50860393 0.50179315
 0.556805   0.5330507  0.5760619  0.57037073 0.5562336  0.5925746
 0.45352754 0.58408785 0.6588705  0.57419235 0.7013661  0.48668912
 0.5687125  0.63294876 0.5209284  0.6879832  0.476964   0.6622156
 0.46792752 0.64801896 0.562215   0.58114165 0.6609634  0.59543574
 0.5680113  0.6870924  0.51176405 0.6266738  0.6989484  0.5373085
 0.64746255 0.5687824  0.5878539  0.7173189  0.63955086 0.63095677
 0.68343425 0.5862972  0.5589439  0.7522503  0.6872468  0.512048
 0.60519326 0.692527   0.5792301  0.5745091  0.5605785  0.67416465
 0.5578067  0.5651932  0.56899846 0.55747    0.50598407 0.6405948
 0.4931145  0.65291166 0.5478202  0.6059609  0.5819439  0.72737074
 0.76334345 0.7239777  0.5798298  0.58079416 0.546057   0.60539126
 0.5627336  0.5686861  0.6618152  0.6211725  0.63172215 0.56055164
 0.70275086 0.55702126 0.55003387 0.7132445  0.69159955 0.5323084
 0.6439926  0.58337075 0.5520518  0.62290347 0.77083236 0.6494194
 0.5749866  0.5507269  0.6992925  0.6752719  0.591002   0.44503942
 0.5583455  0.73824334 0.5708831  0.72916436 0.5233447  0.6434439
 0.6390677  0.66378266 0.54174167 0.63156587 0.68814915 0.7538082
 0.56569487 0.56975836 0.72199893 0.52937657 0.5114308  0.64258987
 0.5765483  0.7032847  0.54265183 0.61944    0.765672   0.5675855
 0.7370564  0.5588153  0.65195525 0.6757745  0.6246186  0.73834145
 0.590372   0.68566746 0.565901   0.694045   0.56027275 0.6863792
 0.49372992 0.55251235 0.5921327  0.5493345  0.5693777  0.7020819
 0.6946885  0.5414709  0.60527194 0.5848228  0.7531434  0.6744113
 0.7460462  0.6834701  0.5134001  0.4539031  0.5032567  0.43409228
 0.5927192  0.5183198  0.73181486 0.58334553 0.56171614 0.5693332
 0.56453544 0.49380362 0.64531636 0.5500393  0.56716824 0.66749763
 0.640142   0.5458956  0.6678051  0.67505646 0.6978565  0.6228111
 0.5361586  0.5304859  0.559334   0.70535785 0.51670724 0.7306472
 0.5863687  0.6820018  0.47087243 0.5546581  0.76064205 0.5528146
 0.5566624  0.7172493  0.5598751  0.53401995 0.6512307  0.55757743
 0.7046708  0.6658829  0.66259557 0.58702374 0.5516122  0.6144201
 0.6354305  0.56736803 0.5397204  0.4985268  0.6908162  0.5719001
 0.59951985 0.5615956  0.4942487  0.66125834 0.64853466 0.53870255
 0.63805    0.55155456 0.5510035  0.6515181  0.5713526  0.5722788
 0.6141774  0.68752885 0.63842654 0.6360475  0.4817622  0.5715167
 0.46401247 0.5671841  0.65888745 0.5640887  0.73220235 0.587135
 0.66554934 0.5099946  0.50890654 0.51516974 0.62524956 0.54075474
 0.70382464 0.5122607  0.581487   0.5788686  0.5947354  0.5678791
 0.560341   0.51566553 0.57453656 0.6607741  0.7573123  0.61198884
 0.5747677  0.63193095 0.58038634 0.6251041  0.6853577  0.70008576
 0.69703305 0.5479117  0.54620314 0.5634457  0.7180308  0.5424965
 0.5741627  0.5933622  0.67456466 0.44585028 0.54512835 0.6917357
 0.55064887 0.7482453  0.6517512  0.51323265 0.7116717  0.6738195
 0.5625836  0.702569   0.66077065 0.6213844  0.62242424 0.728095
 0.6934335  0.6484629  0.55419695 0.6941774  0.59404546 0.58874786
 0.68532485 0.57330686]
video_auc: 0.5198153135821469
label: [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0
 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1
 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1
 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0
 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1]
===> Test Done!
