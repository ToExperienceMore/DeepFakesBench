#!/usr/bin/env python3
"""
ç®€å•ä¸”å¯é çš„CLIPæ¢¯åº¦å¯è§†åŒ–
ä½¿ç”¨è¾“å…¥æ¢¯åº¦æ–¹æ³•ï¼Œæ¯”attention hookæ›´ç›´æ¥å¯é 
"""

import os
import sys
sys.path.append('/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench')
sys.path.append('/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/training')

import torch
import torch.nn.functional as F
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import yaml
import torchvision.transforms as T

from training.detectors.clip_enhanced import CLIPEnhanced

class SimpleGradCAM:
    """
    ç®€å•çš„æ¢¯åº¦å¯è§†åŒ– - åŸºäºè¾“å…¥æ¢¯åº¦çš„æ–¹æ³•
    è¿™ä¸ªæ–¹æ³•æ¯”attention hookæ›´ç›´æ¥ï¼Œé€‚ç”¨äºä»»ä½•æ¨¡å‹
    """
    
    def __init__(self, model):
        self.model = model
        self.model.eval()
        
    def generate_gradcam(self, image_tensor: torch.Tensor, target_class: int = None) -> np.ndarray:
        """
        ç”ŸæˆåŸºäºè¾“å…¥æ¢¯åº¦çš„çƒ­åŠ›å›¾
        Args:
            image_tensor: [1, 3, H, W] è¾“å…¥å›¾åƒtensor
            target_class: ç›®æ ‡ç±»åˆ« (0=Real, 1=Fake)
        Returns:
            gradcam: [H, W] çƒ­åŠ›å›¾
        """
        # ç¡®ä¿è¾“å…¥éœ€è¦æ¢¯åº¦
        image_tensor.requires_grad_(True)
        
        # å‰å‘ä¼ æ’­
        self.model.zero_grad()
        data_dict = {'image': image_tensor}
        pred_dict = self.model(data_dict, inference=True)
        
        # è·å–é¢„æµ‹
        predictions = pred_dict['cls']  # [1, 2]
        probs = pred_dict['prob']       # [1] fake probability
        
        print(f"ğŸ“Š æ¨¡å‹é¢„æµ‹:")
        print(f"   - Fakeæ¦‚ç‡: {probs.item():.4f}")
        print(f"   - é¢„æµ‹ç±»åˆ«: {'Fake' if probs.item() > 0.5 else 'Real'}")
        
        # é€‰æ‹©ç›®æ ‡ç±»åˆ«
        if target_class is None:
            target_class = int(probs.item() > 0.5)
        
        # åå‘ä¼ æ’­è·å–æ¢¯åº¦
        score = predictions[0, target_class]
        score.backward()
        
        # è·å–è¾“å…¥æ¢¯åº¦
        gradients = image_tensor.grad.data  # [1, 3, H, W]
        
        if gradients is None:
            print("âŒ æ— æ³•è·å–æ¢¯åº¦ï¼")
            return np.zeros((image_tensor.shape[2], image_tensor.shape[3]))
        
        print(f"âœ… æˆåŠŸè·å–æ¢¯åº¦: {gradients.shape}")
        
        # è®¡ç®—æ¢¯åº¦çƒ­åŠ›å›¾
        # æ–¹æ³•1: å–æ¢¯åº¦çš„L2èŒƒæ•°
        grad_magnitude = torch.norm(gradients, dim=1, keepdim=True)  # [1, 1, H, W]
        
        # æ–¹æ³•2: å–æ¢¯åº¦çš„ç»å¯¹å€¼ç„¶åæ±‚å’Œ
        # grad_magnitude = torch.sum(torch.abs(gradients), dim=1, keepdim=True)
        
        # è½¬æ¢ä¸ºnumpyå¹¶å½’ä¸€åŒ–
        heatmap = grad_magnitude.squeeze().cpu().numpy()  # [H, W]
        
        # å¢å¼ºå¯¹æ¯”åº¦çš„å½’ä¸€åŒ–
        if heatmap.max() > heatmap.min():
            # å…ˆå½’ä¸€åŒ–åˆ°[0,1]
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
            
            # å¢å¼ºå¯¹æ¯”åº¦ï¼šä½¿ç”¨å¹‚å‡½æ•°çªå‡ºé«˜å€¼åŒºåŸŸ
            heatmap = np.power(heatmap, 0.5)  # å¹³æ–¹æ ¹å˜æ¢ï¼Œè®©ä¸­é«˜å€¼æ›´çªå‡º
            
            # å¯é€‰ï¼šè¿›ä¸€æ­¥å¢å¼ºæœ€é«˜å€¼åŒºåŸŸ
            threshold = np.percentile(heatmap, 90)  # 90%åˆ†ä½æ•°
            heatmap = np.where(heatmap > threshold, heatmap, heatmap * 0.3)  # ä½äºé˜ˆå€¼çš„åŒºåŸŸé™ä½äº®åº¦
        
        print(f"ğŸ“ˆ å¢å¼ºåçƒ­åŠ›å›¾ç»Ÿè®¡:")
        print(f"   - å½¢çŠ¶: {heatmap.shape}")
        print(f"   - æœ€å°å€¼: {heatmap.min():.6f}")
        print(f"   - æœ€å¤§å€¼: {heatmap.max():.6f}")
        print(f"   - å¹³å‡å€¼: {heatmap.mean():.6f}")
        print(f"   - 90%åˆ†ä½æ•°: {np.percentile(heatmap, 90):.6f}")
        
        return heatmap
    
    def visualize_gradcam(self, original_image: np.ndarray, gradcam: np.ndarray, 
                         alpha: float = 0.4) -> np.ndarray:
        """
        å¯è§†åŒ–GradCAM
        """
        # ç¡®ä¿åŸå›¾æ˜¯[0,1]èŒƒå›´
        if original_image.max() > 1:
            original_image = original_image.astype(np.float32) / 255.0
        
        # è°ƒæ•´gradcamå°ºå¯¸åŒ¹é…åŸå›¾
        if gradcam.shape != original_image.shape[:2]:
            gradcam = cv2.resize(gradcam, (original_image.shape[1], original_image.shape[0]))
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        heatmap = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
        heatmap = heatmap.astype(np.float32) / 255.0
        
        # å åŠ 
        visualization = alpha * heatmap + (1 - alpha) * original_image
        
        return np.clip(visualization, 0, 1)

def load_model_and_config(config_path: str, weights_path: str):
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPEnhanced(config)
    
    # åŠ è½½æƒé‡
    if os.path.exists(weights_path):
        checkpoint = torch.load(weights_path, map_location='cpu')
        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        model.load_state_dict(state_dict, strict=False)
        print(f"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
    
    model.eval()
    return model, config

def preprocess_image(image_path: str) -> tuple:
    """é¢„å¤„ç†å›¾åƒ"""
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    original_image = np.array(image)
    
    # é¢„å¤„ç†pipeline
    transform = T.Compose([
        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],
                           std=[0.26862954, 0.26130258, 0.27577711])
    ])
    
    image_tensor = transform(image).unsqueeze(0)
    
    # åŒæ—¶å‡†å¤‡ç”¨äºå¯è§†åŒ–çš„åŸå›¾ï¼ˆresizeåˆ°224x224ï¼‰
    viz_transform = T.Compose([
        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(224),
    ])
    viz_image = np.array(viz_transform(image))
    
    return image_tensor, viz_image

def compare_real_fake_gradcam(model, real_image_path: str, fake_image_path: str, save_dir: str = "real_fake_comparison"):
    """
    å¯¹æ¯”çœŸè„¸å’Œå‡è„¸çš„GradCAMï¼Œç”Ÿæˆå·®åˆ†å›¾
    """
    print("ğŸ” å¼€å§‹çœŸè„¸vså‡è„¸GradCAMå¯¹æ¯”åˆ†æ...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # åˆ›å»ºGradCAM
    gradcam = SimpleGradCAM(model)
    
    # é¢„å¤„ç†ä¸¤å¼ å›¾åƒ
    print("ğŸ“· é¢„å¤„ç†çœŸè„¸å›¾åƒ...")
    real_tensor, real_viz = preprocess_image(real_image_path)
    
    print("ğŸ“· é¢„å¤„ç†å‡è„¸å›¾åƒ...")
    fake_tensor, fake_viz = preprocess_image(fake_image_path)
    
    # åˆ†æçœŸè„¸
    print("\nğŸ§‘ åˆ†æçœŸè„¸...")
    real_heatmap_real_class = gradcam.generate_gradcam(real_tensor.clone(), target_class=0)  # Realç±»åˆ«
    real_heatmap_fake_class = gradcam.generate_gradcam(real_tensor.clone(), target_class=1)  # Fakeç±»åˆ«
    
    # åˆ†æå‡è„¸  
    print("\nğŸ¤– åˆ†æå‡è„¸...")
    fake_heatmap_real_class = gradcam.generate_gradcam(fake_tensor.clone(), target_class=0)  # Realç±»åˆ«
    fake_heatmap_fake_class = gradcam.generate_gradcam(fake_tensor.clone(), target_class=1)  # Fakeç±»åˆ«
    
    # è®¡ç®—å·®åˆ†å›¾
    print("\nğŸ”„ è®¡ç®—å·®åˆ†å›¾...")
    # çœŸè„¸vså‡è„¸åœ¨Realç±»åˆ«ä¸Šçš„å·®å¼‚
    diff_real_class = real_heatmap_real_class - fake_heatmap_real_class
    # çœŸè„¸vså‡è„¸åœ¨Fakeç±»åˆ«ä¸Šçš„å·®å¼‚  
    diff_fake_class = real_heatmap_fake_class - fake_heatmap_fake_class
    
    # å½’ä¸€åŒ–å·®åˆ†å›¾åˆ°[-1, 1]
    def normalize_diff(diff_map):
        max_abs = max(abs(diff_map.min()), abs(diff_map.max()))
        if max_abs > 0:
            return diff_map / max_abs
        return diff_map
    
    diff_real_class = normalize_diff(diff_real_class)
    diff_fake_class = normalize_diff(diff_fake_class)
    
    print(f"ğŸ“Š å·®åˆ†å›¾ç»Ÿè®¡:")
    print(f"   - Realç±»åˆ«å·®åˆ†: [{diff_real_class.min():.3f}, {diff_real_class.max():.3f}]")
    print(f"   - Fakeç±»åˆ«å·®åˆ†: [{diff_fake_class.min():.3f}, {diff_fake_class.max():.3f}]")
    
    # åˆ›å»ºç»¼åˆå¯è§†åŒ–
    fig = plt.figure(figsize=(20, 16))
    
    # ç¬¬ä¸€è¡Œï¼šåŸå›¾
    plt.subplot(4, 5, 1)
    plt.imshow(real_viz)
    plt.title('Real Image', fontsize=12, fontweight='bold')
    plt.axis('off')
    
    plt.subplot(4, 5, 2)
    plt.imshow(fake_viz)
    plt.title('Fake Image', fontsize=12, fontweight='bold')
    plt.axis('off')
    
    # ç¬¬äºŒè¡Œï¼šRealç±»åˆ«çƒ­åŠ›å›¾ - ä½¿ç”¨æ›´æ˜¾çœ¼çš„é¢œè‰²æ˜ å°„
    plt.subplot(4, 5, 6)
    plt.imshow(real_heatmap_real_class, cmap='Reds', vmin=0, vmax=1)
    plt.title('Real Image\nâ†’ Real Class', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Attention')
    
    plt.subplot(4, 5, 7)
    plt.imshow(fake_heatmap_real_class, cmap='Reds', vmin=0, vmax=1)
    plt.title('Fake Image\nâ†’ Real Class', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Attention')
    
    plt.subplot(4, 5, 8)
    plt.imshow(diff_real_class, cmap='RdBu_r', vmin=-1, vmax=1)
    plt.title('Difference\n(Real-Fake)â†’Real', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Diff')
    
    # ç¬¬ä¸‰è¡Œï¼šFakeç±»åˆ«çƒ­åŠ›å›¾ - ä½¿ç”¨æ›´æ˜¾çœ¼çš„é¢œè‰²æ˜ å°„
    plt.subplot(4, 5, 11)
    plt.imshow(real_heatmap_fake_class, cmap='Reds', vmin=0, vmax=1)
    plt.title('Real Image\nâ†’ Fake Class', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Attention')
    
    plt.subplot(4, 5, 12)
    plt.imshow(fake_heatmap_fake_class, cmap='Reds', vmin=0, vmax=1)
    plt.title('Fake Image\nâ†’ Fake Class', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Attention')
    
    plt.subplot(4, 5, 13)
    plt.imshow(diff_fake_class, cmap='RdBu_r', vmin=-1, vmax=1)
    plt.title('Difference\n(Real-Fake)â†’Fake', fontsize=10)
    plt.axis('off')
    plt.colorbar(shrink=0.6, label='Diff')
    
    # ç¬¬å››è¡Œï¼šå åŠ å¯è§†åŒ–
    real_overlay_real = gradcam.visualize_gradcam(real_viz, real_heatmap_real_class)
    fake_overlay_fake = gradcam.visualize_gradcam(fake_viz, fake_heatmap_fake_class)
    
    plt.subplot(4, 5, 16)
    plt.imshow(real_overlay_real)
    plt.title('Realâ†’Real Overlay', fontsize=10)
    plt.axis('off')
    
    plt.subplot(4, 5, 17)
    plt.imshow(fake_overlay_fake)
    plt.title('Fakeâ†’Fake Overlay', fontsize=10)
    plt.axis('off')
    
    plt.suptitle('Real vs Fake GradCAM Comparison & Difference Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    comparison_path = os.path.join(save_dir, 'real_fake_gradcam_comparison.png')
    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {comparison_path}")
    
    return {
        'real_heatmap_real': real_heatmap_real_class,
        'real_heatmap_fake': real_heatmap_fake_class,
        'fake_heatmap_real': fake_heatmap_real_class,
        'fake_heatmap_fake': fake_heatmap_fake_class,
        'diff_real_class': diff_real_class,
        'diff_fake_class': diff_fake_class
    }

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    config_path = "training/config/detector/clip_enhanced.yaml"
    weights_path = "./logs/training/clip_enhanced_2025-06-01-19-22-52/test/avg/ckpt_best.pth"
    
    # ğŸ”§ å›¾åƒè·¯å¾„é…ç½® - ä½ å¯ä»¥ä¿®æ”¹è¿™äº›è·¯å¾„
    #fake_image_path = "/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/datasets/rgb/FaceForensics++/manipulated_sequences/FaceSwap/c23/frames/000_003/000.png"
    fake_image_path="/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/datasets/rgb/FaceForensics++/manipulated_sequences/Face2Face/c23/frames/000_003/000.png"
    real_image_path = "/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/datasets/rgb/FaceForensics++/original_sequences/youtube/c23/frames/000/000.png"
    #real_image_path = "/root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/datasets/rgb/FaceForensics++/original_sequences/youtube/c23/frames/999/150.png"
    
    print("ğŸš€ å¼€å§‹çœŸè„¸vså‡è„¸GradCAMå¯¹æ¯”åˆ†æ...")
    print(f"ğŸ“‚ å‡è„¸å›¾åƒ: {os.path.basename(fake_image_path)}")
    print(f"ğŸ“‚ çœŸè„¸å›¾åƒ: {os.path.basename(real_image_path)}")
    
    # æ£€æŸ¥æ–‡ä»¶
    paths_to_check = [
        (config_path, "é…ç½®æ–‡ä»¶"),
        (weights_path, "æƒé‡æ–‡ä»¶"), 
        (fake_image_path, "å‡è„¸å›¾åƒ"),
        (real_image_path, "çœŸè„¸å›¾åƒ")
    ]
    
    for path, name in paths_to_check:
        if not os.path.exists(path):
            print(f"âŒ {name}ä¸å­˜åœ¨: {path}")
            return
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ“ åŠ è½½æ¨¡å‹...")
        model, config = load_model_and_config(config_path, weights_path)
        
        # æ‰§è¡ŒçœŸè„¸vså‡è„¸å¯¹æ¯”åˆ†æ
        results = compare_real_fake_gradcam(model, real_image_path, fake_image_path)
        
        print("\nğŸ¯ åˆ†ææ€»ç»“:")
        print("=" * 60)
        print("ğŸ“Š çƒ­åŠ›å›¾é¢œè‰²è§£è¯»:")
        print("   - âšª ç™½è‰²ï¼šæ¨¡å‹ä¸å…³æ³¨çš„åŒºåŸŸï¼ˆæ¢¯åº¦å¾ˆå°ï¼‰")
        print("   - ğŸŸ¨ æ·¡çº¢è‰²ï¼šæ¨¡å‹æœ‰ä¸€å®šå…³æ³¨çš„åŒºåŸŸ")
        print("   - ğŸ”´ æ·±çº¢è‰²ï¼šæ¨¡å‹é«˜åº¦å…³æ³¨çš„åŒºåŸŸï¼ˆæ¢¯åº¦å¾ˆå¤§ï¼‰")
        print("")
        print("ğŸ“Š å·®åˆ†å›¾é¢œè‰²è§£è¯»:")
        print("   - ğŸ”´ çº¢è‰²ï¼šçœŸè„¸åœ¨è¯¥ä½ç½®çš„å…³æ³¨åº¦ > å‡è„¸")
        print("   - ğŸ”µ è“è‰²ï¼šå‡è„¸åœ¨è¯¥ä½ç½®çš„å…³æ³¨åº¦ > çœŸè„¸") 
        print("   - âšª ç™½è‰²ï¼šä¸¤è€…å…³æ³¨åº¦ç›¸ä¼¼")
        print("")
        print("ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: real_fake_comparison/")
        print("ğŸ” ç°åœ¨å…³æ³¨åŒºåŸŸåº”è¯¥æ›´åŠ æ˜æ˜¾äº†ï¼")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
