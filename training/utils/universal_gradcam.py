"""
Unified Grad-CAM Implementation
Supports multiple model architectures: Xception, CLIP Enhanced, etc.

Main Features:
1. Automatic model type identification
2. Unified Grad-CAM interface
3. Support for different visualization methods
4. Inter-model comparison analysis

Author: AI Assistant
Date: 2024-12
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.transforms as T
import os
from typing import Union, Dict, Any, Tuple
from abc import ABC, abstractmethod

class BaseGradCAM(ABC):
    """Base class for Grad-CAM"""
    
    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.model = model
        self.device = device
        self.model.to(device)
        self.model.eval()
        
    @abstractmethod
    def generate_gradcam(self, data_dict: Dict, target_class: int = 1, method: str = 'input_grad') -> np.ndarray:
        """Generate Grad-CAM heatmap"""
        pass
    
    @abstractmethod
    def preprocess_image(self, image_path: str) -> Tuple[Dict, Image.Image]:
        """Preprocess image"""
        pass
    
    def _generate_input_gradient(self, data_dict: Dict, target_class: int) -> np.ndarray:
        """Universal input gradient method"""
        # Get input image and set requires_grad
        image_tensor = data_dict['image'].clone().detach().to(self.device)
        image_tensor.requires_grad_(True)
        
        # Create new data dictionary
        new_data_dict = {'image': image_tensor}
        for key, value in data_dict.items():
            if key != 'image':
                if isinstance(value, torch.Tensor):
                    new_data_dict[key] = value.to(self.device)
                else:
                    new_data_dict[key] = value
        
        # Forward pass
        pred_dict = self.model(new_data_dict, inference=True)
        predictions = pred_dict['cls']
        
        # Select target class score
        score = predictions[0, target_class]
        
        # Backward pass to compute gradients
        self.model.zero_grad()
        score.backward(retain_graph=True)
        
        # Get input gradients
        gradients = image_tensor.grad.data
        
        # Calculate gradient magnitude (L2 norm)
        grad_magnitude = torch.norm(gradients, dim=1)  # [B, H, W]
        
        # Convert to numpy
        heatmap = grad_magnitude.squeeze().cpu().numpy()
        
        # Normalization and contrast enhancement
        if heatmap.max() > heatmap.min():
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
            # Contrast enhancement
            heatmap = np.power(heatmap, 0.5)
            # Highlight high-value regions
            threshold = np.percentile(heatmap, 90)
            heatmap = np.where(heatmap > threshold, heatmap, heatmap * 0.3)
        
        return heatmap

class XceptionGradCAM(BaseGradCAM):
    """Xceptionä¸“ç”¨Grad-CAM"""
    
    def __init__(self, model, target_layer_name='conv4', **kwargs):
        super().__init__(model, **kwargs)
        self.target_layer_name = target_layer_name
        self.target_layer = None
        self.gradients = None
        self.activations = None
        
        # æŸ¥æ‰¾ç›®æ ‡å±‚å¹¶æ³¨å†Œhook
        self._find_target_layer()
        self._register_hooks()
    
    def _find_target_layer(self):
        """æŸ¥æ‰¾ç›®æ ‡å±‚"""
        if hasattr(self.model, 'backbone'):
            backbone = self.model.backbone
        else:
            backbone = self.model
            
        if hasattr(backbone, self.target_layer_name):
            self.target_layer = getattr(backbone, self.target_layer_name)
            print(f"âœ… Xception - æ‰¾åˆ°ç›®æ ‡å±‚: {self.target_layer_name}")
        else:
            print(f"âŒ Xception - æœªæ‰¾åˆ°ç›®æ ‡å±‚: {self.target_layer_name}")
    
    def _register_hooks(self):
        """æ³¨å†Œå‰å‘å’Œåå‘hook"""
        if self.target_layer is not None:
            def forward_hook(module, input, output):
                self.activations = output
                
            def backward_hook(module, grad_input, grad_output):
                self.gradients = grad_output[0]
            
            self.target_layer.register_forward_hook(forward_hook)
            self.target_layer.register_backward_hook(backward_hook)
            print(f"âœ… Xception - å·²ä¸º {self.target_layer_name} æ³¨å†Œhooks")
    
    def generate_gradcam(self, data_dict: Dict, target_class: int = 1, method: str = 'input_grad') -> np.ndarray:
        """ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾"""
        if method == 'input_grad':
            return self._generate_input_gradient(data_dict, target_class)
        elif method == 'standard' and self.target_layer is not None:
            return self._generate_standard_gradcam(data_dict, target_class)
        else:
            print(f"âš ï¸ æ–¹æ³• {method} ä¸å¯ç”¨ï¼Œä½¿ç”¨è¾“å…¥æ¢¯åº¦æ–¹æ³•")
            return self._generate_input_gradient(data_dict, target_class)
    
    def _generate_standard_gradcam(self, data_dict: Dict, target_class: int) -> np.ndarray:
        """ç”Ÿæˆæ ‡å‡†Grad-CAM"""
        # å°†æ•°æ®ç§»åˆ°æ­£ç¡®è®¾å¤‡
        device_data_dict = {}
        for key, value in data_dict.items():
            if isinstance(value, torch.Tensor):
                device_data_dict[key] = value.to(self.device)
            else:
                device_data_dict[key] = value
        
        # å‰å‘ä¼ æ’­
        with torch.enable_grad():
            pred_dict = self.model(device_data_dict, inference=True)
            predictions = pred_dict['cls']
            
            # é€‰æ‹©ç›®æ ‡ç±»åˆ«çš„å¾—åˆ†
            score = predictions[0, target_class]
            
            # åå‘ä¼ æ’­
            self.model.zero_grad()
            score.backward(retain_graph=True)
            
            # è·å–æ¢¯åº¦å’Œæ¿€æ´»å€¼
            if self.gradients is None or self.activations is None:
                raise ValueError("æœªèƒ½è·å–æ¢¯åº¦æˆ–æ¿€æ´»å€¼")
            
            # è®¡ç®—æƒé‡ (å…¨å±€å¹³å‡æ± åŒ–)
            weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
            
            # åŠ æƒæ±‚å’Œ
            cam = torch.sum(weights * self.activations, dim=1)
            
            # ReLUç¡®ä¿åªä¿ç•™æ­£è´¡çŒ®
            cam = F.relu(cam)
            
            # è½¬æ¢ä¸ºnumpy
            heatmap = cam.squeeze().detach().cpu().numpy()
            
            # å½’ä¸€åŒ–åˆ°[0,1]
            if heatmap.max() > heatmap.min():
                heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
            
            return heatmap
    
    def preprocess_image(self, image_path: str, resolution: int = 256) -> Tuple[Dict, Image.Image]:
        """é¢„å¤„ç†å›¾åƒ"""
        image = Image.open(image_path).convert('RGB')
        
        transform = T.Compose([
            T.Resize((resolution, resolution)),
            T.ToTensor(),
            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        image_tensor = transform(image).unsqueeze(0)
        data_dict = {'image': image_tensor}
        
        return data_dict, image

class CLIPEnhancedGradCAM(BaseGradCAM):
    """CLIP Enhancedä¸“ç”¨Grad-CAM"""
    
    def __init__(self, model, **kwargs):
        super().__init__(model, **kwargs)
        self.clip_path = getattr(model, 'clip_path', None)
        print(f"âœ… CLIP Enhanced - åˆå§‹åŒ–å®Œæˆ")
    
    def generate_gradcam(self, data_dict: Dict, target_class: int = 1, method: str = 'input_grad') -> np.ndarray:
        """ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾"""
        # CLIP Enhancedä¸»è¦ä½¿ç”¨è¾“å…¥æ¢¯åº¦æ–¹æ³•ï¼Œå› ä¸ºPEFTåŒ…è£…ä½¿å¾—attention hookå¤æ‚
        return self._generate_input_gradient(data_dict, target_class)
    
    def preprocess_image(self, image_path: str) -> Tuple[Dict, Image.Image]:
        """é¢„å¤„ç†å›¾åƒ - ä½¿ç”¨CLIPçš„é¢„å¤„ç†æ–¹å¼"""
        image = Image.open(image_path).convert('RGB')
        
        # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„é¢„å¤„ç†
        transform = T.Compose([
            T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
            T.CenterCrop(224),
            T.ToTensor(),
            T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], 
                       std=[0.26862954, 0.26130258, 0.27577711])
        ])
        
        image_tensor = transform(image).unsqueeze(0)
        data_dict = {'image': image_tensor}
        
        return data_dict, image

class UniversalGradCAM:
    """ç»Ÿä¸€çš„Grad-CAMæ¥å£"""
    
    def __init__(self, model, model_type: str = 'auto', **kwargs):
        """
        åˆå§‹åŒ–ç»Ÿä¸€Grad-CAM
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            model_type: æ¨¡å‹ç±»å‹ ('auto', 'xception', 'clip_enhanced')
            **kwargs: ä¼ é€’ç»™å…·ä½“GradCAMå®ç°çš„å‚æ•°
        """
        self.model = model
        self.model_type = self._detect_model_type(model) if model_type == 'auto' else model_type
        
        # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºå¯¹åº”çš„GradCAMå®ç°
        if self.model_type == 'xception':
            self.gradcam = XceptionGradCAM(model, **kwargs)
        elif self.model_type == 'clip_enhanced':
            self.gradcam = CLIPEnhancedGradCAM(model, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
        
        print(f"ğŸ”§ å·²åˆ›å»º {self.model_type} ç±»å‹çš„Grad-CAM")
    
    def _detect_model_type(self, model) -> str:
        """è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹"""
        model_class_name = type(model).__name__
        
        if 'Xception' in model_class_name or 'xception' in model_class_name.lower():
            return 'xception'
        elif 'CLIP' in model_class_name or 'clip' in model_class_name.lower():
            return 'clip_enhanced'
        else:
            # å°è¯•é€šè¿‡å±æ€§æ£€æµ‹
            if hasattr(model, 'feature_extractor') and hasattr(model, 'clip_path'):
                return 'clip_enhanced'
            elif hasattr(model, 'backbone') and hasattr(model.backbone, 'conv4'):
                return 'xception'
            else:
                print(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹: {model_class_name}")
                return 'unknown'
    
    def generate_gradcam(self, image_path: str, target_class: int = 1, method: str = 'input_grad') -> Tuple[np.ndarray, Image.Image]:
        """
        ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            target_class: ç›®æ ‡ç±»åˆ«
            method: æ–¹æ³•ç±»å‹
            
        Returns:
            heatmap: çƒ­åŠ›å›¾
            original_image: åŸå§‹å›¾åƒ
        """
        # é¢„å¤„ç†å›¾åƒ
        data_dict, original_image = self.gradcam.preprocess_image(image_path)
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        heatmap = self.gradcam.generate_gradcam(data_dict, target_class, method)
        
        return heatmap, original_image
    
    def visualize_gradcam(self, image_path: str, target_class: int = 1, method: str = 'input_grad', 
                         save_path: str = None, alpha: float = 0.4) -> np.ndarray:
        """
        å¯è§†åŒ–Grad-CAMç»“æœ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            target_class: ç›®æ ‡ç±»åˆ«
            method: æ–¹æ³•ç±»å‹
            save_path: ä¿å­˜è·¯å¾„
            alpha: çƒ­åŠ›å›¾é€æ˜åº¦
            
        Returns:
            overlay: å åŠ å›¾åƒ
        """
        # ç”Ÿæˆçƒ­åŠ›å›¾
        heatmap, original_image = self.generate_gradcam(image_path, target_class, method)
        
        # å¯è§†åŒ–
        overlay = self._visualize_heatmap(original_image, heatmap, save_path, alpha)
        
        return overlay
    
    def _visualize_heatmap(self, image: Image.Image, heatmap: np.ndarray, 
                          save_path: str = None, alpha: float = 0.4) -> np.ndarray:
        """å¯è§†åŒ–çƒ­åŠ›å›¾"""
        # å°†åŸå§‹å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        
        # è°ƒæ•´çƒ­åŠ›å›¾å°ºå¯¸ä»¥åŒ¹é…åŸå§‹å›¾åƒ
        h, w = img_array.shape[:2]
        heatmap_resized = cv2.resize(heatmap, (w, h))
        
        # åˆ›å»ºçƒ­åŠ›å›¾çš„å½©è‰²ç‰ˆæœ¬
        heatmap_colored = plt.cm.Reds(heatmap_resized)[:, :, :3]
        heatmap_colored = (heatmap_colored * 255).astype(np.uint8)
        
        # å åŠ çƒ­åŠ›å›¾åˆ°åŸå§‹å›¾åƒ
        overlay = cv2.addWeighted(img_array, 1-alpha, heatmap_colored, alpha, 0)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åŸå§‹å›¾åƒ
        axes[0].imshow(img_array)
        axes[0].set_title('åŸå§‹å›¾åƒ')
        axes[0].axis('off')
        
        # çƒ­åŠ›å›¾
        im = axes[1].imshow(heatmap_resized, cmap='Reds', vmin=0, vmax=1)
        axes[1].set_title(f'{self.model_type.upper()} Grad-CAM')
        axes[1].axis('off')
        plt.colorbar(im, ax=axes[1], shrink=0.6, label='Attention')
        
        # å åŠ å›¾åƒ
        axes[2].imshow(overlay)
        axes[2].set_title('å åŠ å›¾åƒ')
        axes[2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ’¾ {self.model_type} å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return overlay
    
    def compare_models(self, image_path: str, other_gradcam: 'UniversalGradCAM', 
                      target_class: int = 1, save_dir: str = './comparison_results'):
        """
        æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„Grad-CAMç»“æœ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            other_gradcam: å¦ä¸€ä¸ªGradCAMå¯¹è±¡
            target_class: ç›®æ ‡ç±»åˆ«
            save_dir: ä¿å­˜ç›®å½•
        """
        os.makedirs(save_dir, exist_ok=True)
        
        # ç”Ÿæˆä¸¤ä¸ªæ¨¡å‹çš„çƒ­åŠ›å›¾
        heatmap1, image1 = self.generate_gradcam(image_path, target_class)
        heatmap2, image2 = other_gradcam.generate_gradcam(image_path, target_class)
        
        # åˆ›å»ºæ¯”è¾ƒå¯è§†åŒ–
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        models = [
            (self, heatmap1, image1, self.model_type),
            (other_gradcam, heatmap2, image2, other_gradcam.model_type)
        ]
        
        for i, (gradcam_obj, heatmap, image, model_name) in enumerate(models):
            img_array = np.array(image)
            h, w = img_array.shape[:2]
            heatmap_resized = cv2.resize(heatmap, (w, h))
            heatmap_colored = plt.cm.Reds(heatmap_resized)[:, :, :3]
            heatmap_colored = (heatmap_colored * 255).astype(np.uint8)
            overlay = cv2.addWeighted(img_array, 0.6, heatmap_colored, 0.4, 0)
            
            # åŸå§‹å›¾åƒ
            axes[i, 0].imshow(img_array)
            axes[i, 0].set_title(f'{model_name.upper()} - åŸå§‹å›¾åƒ')
            axes[i, 0].axis('off')
            
            # çƒ­åŠ›å›¾
            im = axes[i, 1].imshow(heatmap_resized, cmap='Reds', vmin=0, vmax=1)
            axes[i, 1].set_title(f'{model_name.upper()} - çƒ­åŠ›å›¾')
            axes[i, 1].axis('off')
            plt.colorbar(im, ax=axes[i, 1], shrink=0.6)
            
            # å åŠ å›¾åƒ
            axes[i, 2].imshow(overlay)
            axes[i, 2].set_title(f'{model_name.upper()} - å åŠ ç»“æœ')
            axes[i, 2].axis('off')
        
        plt.tight_layout()
        save_path = os.path.join(save_dir, f'model_comparison_{self.model_type}_vs_{other_gradcam.model_type}.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ’¾ æ¨¡å‹æ¯”è¾ƒç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

# ä¾¿åˆ©å‡½æ•°
def create_gradcam(model, model_type: str = 'auto', **kwargs) -> UniversalGradCAM:
    """åˆ›å»ºGrad-CAMå¯¹è±¡çš„ä¾¿åˆ©å‡½æ•°"""
    return UniversalGradCAM(model, model_type, **kwargs)

def load_model_and_create_gradcam(config_path: str, weights_path: str, model_type: str = 'auto'):
    """åŠ è½½æ¨¡å‹å¹¶åˆ›å»ºGrad-CAMå¯¹è±¡"""
    import yaml
    import sys
    sys.path.append('training')
    from detectors import DETECTOR
    
    # è¯»å–é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # æ›´æ–°æƒé‡è·¯å¾„
    if 'pretrained' in config:
        config['pretrained'] = weights_path
    elif 'weight' in config:
        config['weight'] = weights_path
    
    # åˆ›å»ºæ¨¡å‹
    detector_class = DETECTOR[config['model_name']]
    model = detector_class(config)
    
    # åˆ›å»ºGrad-CAM
    gradcam = create_gradcam(model, model_type)
    
    return model, gradcam

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ”§ ç»Ÿä¸€Grad-CAMå·¥å…·")
    print("æ”¯æŒçš„æ¨¡å‹ç±»å‹: Xception, CLIP Enhanced")
    print("è¯·åœ¨å®é™…ä½¿ç”¨æ—¶å¯¼å…¥æ­¤æ¨¡å—å¹¶åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
