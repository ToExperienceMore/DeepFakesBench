# model setting
pretrained: /root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/training/pretrained/dinov2_vitl14_reg4_pretrain.pth # use pretrained DINOv2
model_name: tall_dinov2 # model name
backbone_name: dinov2  # backbone name

# DINOv2 settings
backbone_config:
  num_classes: 2
  pretrained: true
  dropout: 0.1

# DINOv2 settings for detector
dinov2:
  pretrained: true
  freeze_backbone: true  # freeze DINOv2 parameters

# Layout-aware transformer settings
transformer:
  input_dim: 1024  # DINOv2-L output dimension
  hidden_dim: 2048
  num_layers: 4
  num_heads: 8
  dropout: 0.1

# Classification head settings
classifier:
  hidden_dim: 512
  dropout: 0.1
  num_classes: 2

# dataset
all_dataset: [FaceForensics++, FF-F2F, FF-DF, FF-FS, FF-NT, FaceShifter, DeepFakeDetection, Celeb-DF-v1, Celeb-DF-v2, DFDCP, DFDC, DeeperForensics-1.0, UADFV]
train_dataset: [FaceForensics++]
test_dataset: [Celeb-DF-v2]

compression: c23  # compression-level for videos
train_batchSize: 32   # training batch size
test_batchSize: 32   # test batch size
workers: 4   # number of data loading workers
frame_num: {'train': 32, 'test': 32}   # number of frames to use per video
resolution: 224   # resolution of output image to network
with_mask: false   # whether to include mask information in the input
with_landmark: false   # whether to include facial landmark information in the input
video_mode: True  # whether to use video-level data
clip_size: 4  # number of frames in each clip, should be square number of an integer
#dataset_type: tall

# data augmentation
use_data_augmentation: false
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [-10, 10]
  blur_prob: 0.5
  blur_limit: [3, 7]
  brightness_prob: 0.5
  brightness_limit: [-0.1, 0.1]
  contrast_limit: [-0.1, 0.1]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# optimizer config
optimizer:
  type: adam
  adam:
    lr: 0.00002
    beta1: 0.9
    beta2: 0.999
    eps: 0.00000001
    weight_decay: 0.0005
    amsgrad: false
  sgd:
    lr: 0.0002
    momentum: 0.9
    weight_decay: 0.0005

# training config
lr_scheduler: null
nEpochs: 100
start_epoch: 0
save_epoch: 1
rec_iter: 100
logdir: ./logs
manualSeed: 1024
save_ckpt: true
save_feat: true

# loss function
loss_func: cross_entropy
losstype: null

# metric
metric_scoring: auc

# cuda
cuda: true
cudnn: true 