# CLIP ViT Attention å¯è§†åŒ–æŒ‡å—

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

è¿™ä¸ªå·¥å…·å®ç°äº†**æ¢¯åº¦åŠ æƒattentionå¯è§†åŒ–**ï¼Œä¸“é—¨ç”¨äºåˆ†æä½ çš„CLIP deepfakeæ£€æµ‹æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚

### æ ¸å¿ƒåŸç†
```
è¾“å…¥å›¾åƒ â†’ CLIP ViT â†’ Multi-Head Attention â†’ æ¢¯åº¦åŠ æƒ â†’ å¯è§†åŒ–çƒ­åŠ›å›¾
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æµ‹è¯•å›¾åƒ
```bash
# å°†ä½ è¦åˆ†æçš„å›¾åƒæ”¾åˆ°é¡¹ç›®æ ¹ç›®å½•
cp your_test_image.jpg /root/autodl-tmp/benchmark_deepfakes/DeepfakeBench/test_image.jpg
```

### 2. è¿è¡Œå¯è§†åŒ–
```bash
cd /root/autodl-tmp/benchmark_deepfakes/DeepfakeBench
python examples/clip_attention_visualization.py
```

### 3. æŸ¥çœ‹ç»“æœ
ç»“æœä¼šä¿å­˜åœ¨ `attention_results/` ç›®å½•ä¸‹ï¼š
- `*_real_attention.png` - Realç±»åˆ«çš„attention
- `*_fake_attention.png` - Fakeç±»åˆ«çš„attention  
- `*_comparison.png` - å¯¹æ¯”åˆ†æå›¾

## ğŸ“‹ è¯¦ç»†ä½¿ç”¨è¯´æ˜

### ä¿®æ”¹é…ç½®è·¯å¾„

åœ¨ `examples/clip_attention_visualization.py` çš„ `main()` å‡½æ•°ä¸­ä¿®æ”¹ï¼š

```python
def main():
    # ğŸ”§ ä¿®æ”¹è¿™äº›è·¯å¾„
    model_config_path = "training/config/detector/clip_enhanced.yaml"  # ä½ çš„é…ç½®æ–‡ä»¶
    weights_path = "path/to/your/model_weights.pth"  # ä½ çš„æ¨¡å‹æƒé‡
    test_image_path = "test_image.jpg"  # æµ‹è¯•å›¾åƒ
```

### è‡ªå®šä¹‰åˆ†æå‚æ•°

```python
# åœ¨analyze_single_imageå‡½æ•°ä¸­ä¿®æ”¹
gradcam = CLIPViTGradCAM(
    model, 
    target_layers=[-4, -3, -2, -1],  # åˆ†æçš„å±‚ï¼šæœ€å4å±‚
    head_fusion="mean"               # å¤šå¤´èåˆæ–¹å¼ï¼šmean/max/min
)
```

## ğŸ¨ å¯è§†åŒ–ç»“æœè§£è¯»

### 1. Real Class Attention
- **é«˜äº®åŒºåŸŸ**ï¼šæ¨¡å‹è®¤ä¸º"çœ‹èµ·æ¥çœŸå®"çš„åŒºåŸŸ
- **æš—è‰²åŒºåŸŸ**ï¼šå¯¹Realåˆ†ç±»è´¡çŒ®è¾ƒå°çš„åŒºåŸŸ

### 2. Fake Class Attention  
- **é«˜äº®åŒºåŸŸ**ï¼šæ¨¡å‹æ£€æµ‹åˆ°çš„"ä¼ªé€ ç—•è¿¹"åŒºåŸŸ
- **å¸¸è§æ¨¡å¼**ï¼šé¢éƒ¨è¾¹ç¼˜ã€çœ¼éƒ¨ã€å˜´éƒ¨å¼‚å¸¸åŒºåŸŸ

### 3. å¯¹æ¯”åˆ†æ
- **å·®å¼‚åŒºåŸŸ**ï¼šRealå’ŒFake attentionçš„ä¸åŒå…³æ³¨ç‚¹
- **é‡å åŒºåŸŸ**ï¼šä¸¤ç±»å…±åŒå…³æ³¨çš„é‡è¦ç‰¹å¾

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. å¤šå±‚åˆ†æ
è¿è¡Œæ—¶é€‰æ‹©"y"è¿›è¡Œå¤šå±‚åˆ†æï¼ŒæŸ¥çœ‹ä¸åŒå±‚çš„attentionæ¨¡å¼ï¼š
- `last_layer` - æœ€åä¸€å±‚ï¼ˆæœ€å…·ä½“çš„ç‰¹å¾ï¼‰
- `last_4_layers` - æœ€å4å±‚ï¼ˆæ¨èï¼‰
- `all_layers` - æ‰€æœ‰å±‚ï¼ˆæœ€å…¨é¢ï¼‰

### 2. æ‰¹é‡åˆ†æ
ä¿®æ”¹è„šæœ¬æ”¯æŒæ‰¹é‡å¤„ç†å¤šå¼ å›¾åƒï¼š

```python
# åœ¨analyze_single_imageåŸºç¡€ä¸Šæ‰©å±•
image_list = ["image1.jpg", "image2.jpg", "image3.jpg"]
for img_path in image_list:
    analyze_single_image(config_path, weights_path, img_path)
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```
   âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨
   ```
   - æ£€æŸ¥ `weights_path` æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æƒé‡æ–‡ä»¶å­˜åœ¨

2. **CUDAå†…å­˜ä¸è¶³**
   ```python
   # åœ¨è„šæœ¬å¼€å¤´æ·»åŠ 
   import torch
   torch.cuda.empty_cache()
   ```

3. **attentionæƒé‡ä¸ºç©º**
   ```
   No attention weights found
   ```
   - æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
   - ç¡®ä¿ä½¿ç”¨çš„æ˜¯CLIP vision model

4. **å›¾åƒé¢„å¤„ç†é”™è¯¯**
   ```python
   # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
   image = Image.open(image_path).convert('RGB')
   ```

### è°ƒè¯•æ¨¡å¼

æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼š
```python
# åœ¨CLIPViTGradCAMç±»ä¸­æ·»åŠ 
def _debug_info(self):
    print(f"Target layers: {self.target_layers}")
    print(f"Attention weights keys: {list(self.attention_weights.keys())}")
    print(f"Attention gradients keys: {list(self.attention_gradients.keys())}")
```

## ğŸ“Š ç»“æœåˆ†æå»ºè®®

### 1. çœŸå®å›¾åƒçš„ç‰¹å¾
- attentioné€šå¸¸åˆ†å¸ƒåœ¨**é¢éƒ¨ç»“æ„**ä¸Š
- çœ¼éƒ¨ã€é¼»éƒ¨ã€å˜´éƒ¨æœ‰**å‡åŒ€å…³æ³¨**
- è¾¹ç¼˜åŒºåŸŸattentionè¾ƒ**å¼±**

### 2. ä¼ªé€ å›¾åƒçš„ç‰¹å¾  
- attentioné›†ä¸­åœ¨**å¼‚å¸¸åŒºåŸŸ**
- **è¾¹ç•Œçº¿**ã€**ä¸è‡ªç„¶è¿‡æ¸¡**å¤„é«˜äº®
- å¯èƒ½åœ¨**èƒŒæ™¯èåˆ**å¤„æœ‰å¼‚å¸¸

### 3. æ¨¡å‹å¯è§£é‡Šæ€§
- **é«˜ç½®ä¿¡åº¦åŒºåŸŸ**ï¼šattentionå¼ºä¸”é›†ä¸­
- **è¾¹ç•Œæƒ…å†µ**ï¼šattentionåˆ†æ•£æˆ–çŸ›ç›¾
- **å¤±è´¥æ¡ˆä¾‹**ï¼šattentionä¸äººç±»ç›´è§‰ä¸ç¬¦

## ğŸ“š æ‰©å±•é˜…è¯»

- [Attention RolloutåŸç†](https://arxiv.org/abs/2005.00928)
- [ViTå¯è§£é‡Šæ€§ç ”ç©¶](https://arxiv.org/abs/2010.11929)  
- [Transformer Attentionå¯è§†åŒ–](https://arxiv.org/abs/1906.04341)

## ğŸ¤ è´¡çŒ®ä¸åé¦ˆ

å¦‚æœä½ å‘ç°bugæˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š
1. æ£€æŸ¥ç°æœ‰issues
2. æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œå¤ç°æ­¥éª¤
3. åˆ†äº«ä½ çš„ä½¿ç”¨åœºæ™¯å’Œç»“æœ

---

**å¼€å§‹ä½ çš„attentionå¯è§†åŒ–ä¹‹æ—…å§ï¼** ğŸš€
