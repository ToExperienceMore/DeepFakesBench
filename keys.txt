+ python3 training/test.py --detector_path ./training/config/detector/clip_enhanced.yaml --test_dataset FaceForensics++ --weights_path ../deepfake-detection/weights/model.ckpt
['in_channels', 'out_channels', 'kernel_size', 'stride', 'padding', 'dilation', 'groups', 'bias', 'padding_mode', 'device', 'dtype']
spatial_count=0 keep_stride_count=0
model keys:
['feature_extractor.vision_model.embeddings.class_embedding', 'feature_extractor.vision_model.embeddings.patch_embedding.weight', 'feature_extractor.vision_model.embeddings.position_embedding.weight', 'feature_extractor.vision_model.pre_layrnorm.base_layer.weight', 'feature_extractor.vision_model.pre_layrnorm.base_layer.bias', 'feature_extractor.vision_model.pre_layrnorm.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.pre_layrnorm.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.0.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.1.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.2.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.3.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.4.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.5.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.6.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.7.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.8.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.9.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.10.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.11.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.12.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.13.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.14.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.15.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.16.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.17.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.18.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.19.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.20.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.21.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.22.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'feature_extractor.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc1.weight', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc1.bias', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc2.weight', 'feature_extractor.vision_model.encoder.layers.23.mlp.fc2.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.base_layer.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.base_layer.bias', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.vision_model.post_layernorm.base_layer.weight', 'feature_extractor.vision_model.post_layernorm.base_layer.bias', 'feature_extractor.vision_model.post_layernorm.ln_tuning_layers.default.weight', 'feature_extractor.vision_model.post_layernorm.ln_tuning_layers.default.bias', 'model.linear.weight', 'model.linear.bias']


ckpt keys:
['feature_extractor.base_model.model.vision_model.embeddings.class_embedding', 'feature_extractor.base_model.model.vision_model.embeddings.patch_embedding.weight', 'feature_extractor.base_model.model.vision_model.embeddings.position_embedding.weight', 'feature_extractor.base_model.model.vision_model.pre_layrnorm.base_layer.weight', 'feature_extractor.base_model.model.vision_model.pre_layrnorm.base_layer.bias', 'feature_extractor.base_model.model.vision_model.pre_layrnorm.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.pre_layrnorm.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.0.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.1.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.2.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.3.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.4.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.5.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.6.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.7.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.8.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.9.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.10.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.11.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.12.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.13.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.14.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.15.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.16.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.17.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.18.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.19.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.20.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.21.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.22.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm1.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm1.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm1.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.mlp.fc1.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.mlp.fc1.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.mlp.fc2.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.mlp.fc2.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm2.base_layer.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm2.base_layer.bias', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.encoder.layers.23.layer_norm2.ln_tuning_layers.default.bias', 'feature_extractor.base_model.model.vision_model.post_layernorm.base_layer.weight', 'feature_extractor.base_model.model.vision_model.post_layernorm.base_layer.bias', 'feature_extractor.base_model.model.vision_model.post_layernorm.ln_tuning_layers.default.weight', 'feature_extractor.base_model.model.vision_model.post_layernorm.ln_tuning_layers.default.bias', 'model.linear.weight', 'model.linear.bias']
===> Load checkpoint done!

Dataset: FaceForensics++
Number of images: 22388
Number of labels: 22388

  0%|          | 0/10 [00:00<?, ?it/s]
 10%|         | 1/10 [00:00<00:08,  1.03it/s]
 20%|        | 2/10 [00:01<00:05,  1.40it/s]
 30%|       | 3/10 [00:02<00:04,  1.58it/s]
 40%|      | 4/10 [00:02<00:03,  1.68it/s]
 50%|     | 5/10 [00:03<00:02,  1.74it/s]
 60%|    | 6/10 [00:03<00:02,  1.79it/s]
 70%|   | 7/10 [00:04<00:01,  1.81it/s]
 80%|  | 8/10 [00:04<00:01,  1.83it/s]
 90%| | 9/10 [00:05<00:00,  1.84it/s]
100%|| 10/10 [00:05<00:00,  1.85it/s]
100%|| 10/10 [00:05<00:00,  1.73it/s]

Detailed metrics for FaceForensics++:
True Negatives (Real classified as Real): 0
False Positives (Real classified as Fake): 62
False Negatives (Fake classified as Real): 0
True Positives (Fake classified as Fake): 258
Accuracy: 0.8063
Precision: 0.8063
Recall: 1.0000
F1 Score: 0.8927

Predictions shape: (320,)
Labels shape: (320,)
Number of processed images: 22388
Number of processed image names: 320
len(y_pred): 320
len(y_true): 320

dataset: FaceForensics++
acc: 0.80625
auc: 0.6149662415603901
eer: 0.4032258064516129
ap: 0.8681188243998275
pred: [0.97722214 0.7089563  0.97267544 0.83774316 0.8711972  0.9247432
 0.8946612  0.9546183  0.95871896 0.967605   0.985196   0.9459389
 0.85742944 0.9469081  0.92348295 0.8802466  0.86578375 0.96103024
 0.98146695 0.91373914 0.9307559  0.875182   0.95611644 0.9769264
 0.945387   0.83155507 0.945746   0.9436853  0.96132207 0.9591713
 0.89901227 0.9795491  0.9257932  0.9377034  0.9665063  0.9268411
 0.9329827  0.9369998  0.8538368  0.9806605  0.91168433 0.96618205
 0.9648454  0.91615605 0.92404175 0.9610742  0.7142463  0.9754744
 0.9091954  0.93361694 0.9879958  0.9732762  0.88542056 0.91788965
 0.8147009  0.9300946  0.94183356 0.97596985 0.9509094  0.96953994
 0.9157366  0.90799814 0.91383344 0.8368739  0.9762576  0.93680924
 0.96571565 0.91380817 0.9742131  0.559054   0.933372   0.9188838
 0.9279237  0.9495781  0.881345   0.98466325 0.9228725  0.6810419
 0.90749395 0.9187851  0.9719447  0.95582706 0.9769339  0.8782994
 0.960549   0.9697445  0.9337148  0.8873995  0.96761906 0.8219611
 0.9780424  0.95222944 0.73831916 0.979152   0.9778711  0.942493
 0.8889241  0.9828205  0.9521555  0.9292274  0.9121364  0.91127807
 0.97331005 0.894408   0.9492724  0.94720256 0.9842531  0.9605317
 0.9430831  0.9244599  0.918524   0.8652497  0.9043849  0.9657345
 0.9526214  0.85062253 0.9532662  0.67615765 0.94925755 0.8818807
 0.9714472  0.913844   0.949534   0.89216584 0.9444541  0.80773
 0.91517013 0.9277901  0.98025185 0.954962   0.9096229  0.94890934
 0.956256   0.88341194 0.9026366  0.9426978  0.9675217  0.7360609
 0.9610703  0.941684   0.9768162  0.9864031  0.9380535  0.99324787
 0.9586358  0.836146   0.8627073  0.91863686 0.9441231  0.94251376
 0.9780628  0.97527474 0.93342954 0.98064834 0.96951354 0.9150831
 0.94535494 0.9620658  0.9794444  0.84780383 0.9328501  0.8542352
 0.8206179  0.9486113  0.9562502  0.95471543 0.986145   0.94196117
 0.9544774  0.9663494  0.9769563  0.9746849  0.95873225 0.8541006
 0.9511221  0.9050853  0.96086293 0.9736659  0.96572477 0.9323487
 0.96466607 0.9660611  0.9010436  0.9580106  0.9592134  0.90841556
 0.92832166 0.89837915 0.9672917  0.5923974  0.94961756 0.9467396
 0.95355    0.96564686 0.97974914 0.9812944  0.96376926 0.96146125
 0.8414823  0.9890247  0.964315   0.913908   0.9339429  0.9345623
 0.970698   0.91072255 0.87806004 0.95048565 0.8442126  0.8104926
 0.8870178  0.92260134 0.9092755  0.9518479  0.9559542  0.8497642
 0.86717683 0.93083286 0.96084785 0.97088313 0.9192012  0.9549156
 0.9794702  0.8682201  0.9633925  0.7065562  0.89801735 0.90742266
 0.870976   0.9095675  0.97731394 0.9642615  0.9388457  0.98728114
 0.964694   0.94963336 0.9225275  0.9016281  0.92236066 0.8710862
 0.9720447  0.92785263 0.98077035 0.94557595 0.99453944 0.97668535
 0.90332454 0.9349752  0.93823886 0.93143934 0.92553157 0.9536713
 0.9470233  0.9292786  0.9597651  0.89908415 0.815508   0.8796642
 0.98516095 0.98131734 0.9428948  0.9488516  0.976232   0.9158687
 0.91070324 0.5699682  0.9761728  0.844871   0.8717988  0.902535
 0.9620502  0.9650383  0.95930666 0.9557005  0.964352   0.97512597
 0.95087254 0.9495509  0.97814023 0.9419079  0.92969745 0.959143
 0.9592748  0.96495163 0.9829274  0.9773809  0.96422076 0.9133783
 0.9787179  0.9760878  0.980451   0.97177887 0.99533194 0.9638758
 0.9153698  0.9278646  0.9342279  0.84530896 0.92561245 0.7219257
 0.96834016 0.9855064  0.93707573 0.9444413  0.9270608  0.93202305
 0.96696275 0.9421824  0.96959215 0.96346515 0.8324167  0.96050763
 0.8896969  0.94795036 0.86910003 0.9574754  0.93419474 0.9854629
 0.8403164  0.96617883]
video_auc: 0.6025394382454792
label: [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0
 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1
 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1
 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0
 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1]
===> Test Done!
